@article{bates2015fitting,
  title = {Fitting Linear Mixed-Effects Models Using {{lme4}}},
  author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01}
}

@article{bender2023instructing,
  title = {Instructing Use of an Effective Strategy Improves Recognition Memory in Healthy Adults},
  author = {Bender, Andrew R. and Driver, Charles C. and Hertzog, Christopher and Raz, Naftali},
  date = {2023-03-04},
  journaltitle = {The Journals of Gerontology. Series B, Psychological Sciences and Social Sciences},
  shortjournal = {J Gerontol B Psychol Sci Soc Sci},
  volume = {78},
  number = {3},
  eprint = {36130328},
  eprinttype = {pubmed},
  pages = {383--393},
  issn = {1758-5368},
  doi = {10.1093/geronb/gbac144},
  abstract = {OBJECTIVES: Age-related memory decrements correlate with metacognitive declines, including knowledge and deployment of effective mnemonic encoding strategies. However, whether imparting such strategy suffices for mitigating memory differences is unclear. METHOD: In a longitudinal study of 276 healthy adults aged 18-79 years, we tested associative and working memory, and assessed beliefs regarding mnemonic strategies. Testing was repeated every 2 years, 5 times. Starting with the third occasion, we instructed participants to use an effective mnemonic strategy (sentence generation). Using continuous-time dynamic modeling, we assessed changes in the item and associative recognition, intervention effects, and their relations with age, sex, meta-memory beliefs, working memory, and metabolic health. RESULTS: Younger age, better working memory, and stronger belief in effective mnemonic strategies predicted better recognition, whereas instructional intervention attenuated associative memory deficits, with some persistence over time. DISCUSSION: The present findings show merely imparting effective strategies holds promise for mitigating age-related associative memory deficits.},
  langid = {english},
  pmcid = {PMC9985315},
  keywords = {Aging,Association Learning,Humans,Intervention,Longitudinal Studies,Memory,Memory Disorders,Memory Short-Term,Metabolic risk,Metacognition,Strategy}
}

@incollection{brandmaier2018Recursive,
  title = {Recursive Partitioning in Continuous Time Analysis},
  booktitle = {Continuous {{Time Modeling}} in the {{Behavioral}} and {{Related Sciences}}},
  author = {Brandmaier, Andreas M. and Driver, Charles C. and Voelkle, Manuel C.},
  editor = {family=Montfort, given=Kees, prefix=van, useprefix=true and Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2018},
  pages = {259--282},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-77219-6_11},
  url = {https://doi.org/10.1007/978-3-319-77219-6_11},
  urldate = {2019-06-26},
  abstract = {Building models fully informed by theory is challenging when data sets are large and strong assumptions about all variables of interest and their interrelations cannot be made. Machine learning-inspired approaches have been gaining momentum in modeling such “big” data because they offer a systematic approach to searching for potential interrelationships among variables. In practice, researchers may often start with a small model strongly guided by theory. In a second step, however, they quickly face the challenge of selecting among additional variables as to whether they should be included in or omitted from the model. This situation calls for both a confirmatory statistical modeling approach and an exploratory statistical learning approach to data analysis within a single framework. Structural equation model (SEM) trees, a combination of SEM and decision trees (also known as classification and regression trees), offer a principled solution to this selection problem. SEM trees hierarchically split empirical data into homogeneous groups sharing similar data patterns by recursively selecting optimal predictors of these differences from a potentially large set of candidate variables. SEM forests are an extension of SEM trees, consisting of ensembles of SEM trees, each built on a random sample of the original data. By aggregating over ensembles of SEM trees (SEM forests), we obtain measures of variable importance that are more robust than measures from single trees. In the present chapter, we combine SEM trees and SEM-based continuous time modeling. The resulting approach of continuous time SEM trees will be illustrated by exploring dynamics in perceptual speed using data from the COGITO study.},
  isbn = {978-3-319-77219-6},
  langid = {english}
}

@article{carpenter2017stan,
  title = {Stan: A Probabilistic Programming Language},
  shorttitle = {\mkbibemph{Stan}},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {76},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  url = {http://www.jstatsoft.org/v76/i01/},
  urldate = {2017-09-01},
  langid = {english},
  keywords = {algorithmic differentiation,Bayesian inference,probabilistic programming,Stan},
  file = {C:\Users\Driver\Zotero\storage\4Y6GNWBM\v076i01.html}
}

@article{driver2017continuous,
  title = {Continuous {{Time Structural Equation Modeling}} with {{R}} Package Ctsem},
  author = {Driver, Charles C. and Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {77},
  number = {5},
  pages = {1--35},
  issn = {1548-7660},
  doi = {10.18637/jss.v077.i05},
  url = {https://www.jstatsoft.org/v077/i05},
  abstract = {We introduce ctsem, an R package for continuous time structural equation modeling of panel (N ¿ 1) and time series (N = 1) data, using full information maximum likelihood. Most dynamic models (e.g., cross-lagged panel models) in the social and behavioural sciences are discrete time models. An assumption of discrete time models is that time intervals between measurements are equal, and that all subjects were assessed at the same intervals. Violations of this assumption are often ignored due to the difficulty of accounting for varying time intervals, therefore parameter estimates can be biased and the time course of effects becomes ambiguous. By using stochastic differential equations to estimate an underlying continuous process, continuous time models allow for any pattern of measurement occasions. By interfacing to OpenMx, ctsem combines the flexible specification of structural equation models with the enhanced data gathering opportunities and improved estimation of continuous time models. ctsem can estimate relationships over time for multiple latent processes, measured by multiple noisy indicators with varying time intervals between observations. Within and between effects are estimated simultaneously by modeling both observed covariates and unobserved heterogeneity. Exogenous shocks with different shapes, group differences, higher order diffusion effects and oscillating processes can all be simply modeled. We first introduce and define continuous time models, then show how to specify and estimate a range of continuous time models using ctsem.},
  keywords = {continuous time,dynamic models,Dynamic models,Kalman filter,longitudinal modeling,Longitudinal modeling,panel data,Panel data,R,state space,stochastic differential equation,structural equation modeling,time series},
  file = {C:\Users\Driver\Zotero\storage\4I4T68BH\Driver et al_2017_Continuous Time Structural Equation Modeling with R package ctsem.pdf}
}

@article{driver2018hierarchical,
  title = {Hierarchical {{Bayesian}} Continuous Time Dynamic Modeling},
  author = {Driver, Charles C and Voelkle, Manuel C},
  date = {2018},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychol Methods},
  volume = {23},
  number = {4},
  pages = {774--799},
  publisher = {American Psychological Association},
  doi = {10.1037/met0000168},
  keywords = {Bayes Theorem,Humans,Individuality,Models Psychological,Models Statistical,Psychology}
}

@incollection{driver2018understanding,
  title = {Understanding the Time Course of Interventions with Continuous Time Dynamic Models},
  booktitle = {Continuous Time Modeling in the Behavioral and Related Sciences},
  author = {Driver, Charles C. and Voelkle, Manuel C.},
  editor = {family=Montfort, given=Kees, prefix=van, useprefix=false and Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2018},
  pages = {79--109},
  publisher = {Springer International Publishing},
  location = {New York},
  url = {//www.springer.com/de/book/9783319772189},
  isbn = {978-3-319-77218-9}
}

@article{driver2021computational,
  title = {Computational Efficiency in Continuous (and Discrete!) Time Models – Comment on {{Hecht}} and {{Zitzmann}}},
  author = {Driver, Charles C},
  date = {2021-02-04},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {28},
  number = {5},
  pages = {791--793},
  issn = {1070-5511},
  doi = {10.1080/10705511.2021.1877547},
  url = {https://doi.org/10.1080/10705511.2021.1877547},
  urldate = {2021-06-17},
  abstract = {Continuous-time models generally imply a stochastic differential equation for latent processes, coupled to a measurement model. Various computational issues can arise, and there are different estimation approaches, with different trade-offs. It has been claimed that a SEM style continuous-time model can reduce run times for Bayesian estimations of continuous-time models from hours to minutes. However this claim is not true in the general case, but requires that individuals are characterized by the same covariance and means structure, and that the number of time points is not large. While such simplifications can be valuable, and indeed are in use in existing software when appropriate, they are in general quite restrictive. The hierarchical Bayesian form of ctsem was, for instance, developed precisely to estimate models where these restrictions do not hold. To try to shed some more light on these aspects, I discuss the related issues herein.},
  keywords = {Continuous time,state space,stochastic differential equation},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\E9ZBFC6L\\Driver - 2021 - Computational Efficiency in Continuous (and Discre.pdf;C\:\\Users\\Driver\\Zotero\\storage\\N94F6NRF\\Driver_2021_Computational efficiency in continuous (and Discrete.pdf;C\:\\Users\\Driver\\Zotero\\storage\\9DDDGPJI\\10705511.2021.html}
}

@incollection{driver2021hierarchical,
  title = {Hierarchical Continuous Time Modeling},
  booktitle = {The Handbook of Personality Dynamics and Processes},
  author = {Driver, Charles C. and Voelkle, Manuel C.},
  editor = {Rauthmann, John F.},
  date = {2021},
  pages = {887--908},
  publisher = {Academic Press},
  url = {https://doi.org/10.1016/B978-0-12-813995-0.00034-0},
  abstract = {We describe the basic usage of the hierarchical formulation of the ctsem software for continuous-time dynamic modeling in R, the scope of which been expanded to include nonlinear models and optimization with optional importance sampling, meaning that the approach described herein largely supersedes the initial mixed effects approach based upon OpenMx, as estimation options now include maximum likelihood, maximum a posteriori, and fully Bayesian. We describe the continuous time dynamic model governing within-subject dynamics, and the hierarchical model governing the distribution of subject-level parameters, then walk through installing the ctsem software, setting up a data structure, specifying and fitting the model, followed by summary and plotting functions. Some details on additional complexity are then provided, including an example model with a more complex dynamic structure, a discussion of the various options for incorporating stationarity assumptions into the model, and a walk-through of the various transformations involved in the model.},
  isbn = {978-0-12-813995-0},
  langid = {english},
  keywords = {Drift,Matrix,Model,Parameter,Population,Prior,Standard,Time},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\FM43EIWH\\B9780128139950000340.html;C\:\\Users\\Driver\\Zotero\\storage\\XQ6D9WRA\\B9780128139950000340.html}
}

@article{driver2023formalizing,
  title = {Formalizing Developmental Phenomena as Continuous-Time Systems: {{Relations}} between Mathematics and Language Development},
  shorttitle = {Formalizing Developmental Phenomena as Continuous-Time Systems},
  author = {Driver, Charles C. and Tomasik, Martin J.},
  date = {2023},
  journaltitle = {Child Development},
  volume = {94},
  number = {6},
  pages = {1454--1471},
  issn = {1467-8624},
  doi = {10.1111/cdev.13990},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13990},
  urldate = {2023-12-04},
  abstract = {We demonstrate how developmental theories may be instantiated as statistical models, using hierarchical continuous-time dynamic systems. This approach offers a flexible specification and an often more direct link between theory and model parameters than common modeling frameworks. We address developmental theories of the relation between the academic competencies of mathematics and language, using data from the online learning system Mindsteps. We use ability estimates from 160,164 observation occasions, across N = 4623 3rd to 9th grade students and five ability domains. Model development is step-by-step from simple to complex, with ramifications for theory and modeling discussed at each step.},
  langid = {english},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\9VFBWYFN\\Driver_Tomasik_2023_Formalizing developmental phenomena as continuous-time systems.pdf;C\:\\Users\\Driver\\Zotero\\storage\\Z6ARTX2K\\Driver_Tomasik_Formalizing developmental phenomena as continuous-time systems.pdf;C\:\\Users\\Driver\\Zotero\\storage\\FYLSEC44\\cdev.html}
}

@article{driver2024inference,
  title = {Inference with Cross-Lagged Effects—{{Problems}} in Time},
  author = {Driver, Charles C.},
  date = {2024},
  journaltitle = {Psychological Methods},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/met0000665},
  abstract = {The interpretation of cross-effects from vector autoregressive models to infer structure and causality among constructs is widespread and sometimes problematic. I describe problems in the interpretation of cross-effects when processes that are thought to fluctuate continuously in time are, as is typically done, modeled as changing only in discrete steps (as in e.g., structural equation modeling)—zeroes in a discrete-time temporal matrix do not necessarily correspond to zero effects in the underlying continuous processes, and vice versa. This has implications for the common case when the presence or absence of cross-effects is used for inference about underlying causal processes. I demonstrate these problems via simulation, and also show that when an underlying set of processes are continuous in time, even relatively few direct causal links can result in much denser temporal effect matrices in discrete-time. I demonstrate one solution to these issues, namely parameterizing the system as a stochastic differential equation and focusing inference on the continuous-time temporal effects. I follow this with some discussion of issues regarding the switch to continuous-time, specifically regularization, appropriate measurement time lag, and model order. An empirical example using intensive longitudinal data highlights some of the complexities of applying such approaches to real data, particularly with respect to model specification, examining misspecification, and parameter interpretation. (PsycInfo Database Record (c) 2024 APA, all rights reserved)},
  keywords = {Inference,Statistical Data,Statistical Inference,Stochastic Modeling,Time Series},
  file = {C:\Users\Driver\Zotero\storage\UCR6MC8B\2025-04049-001.html}
}

@article{gabry2019visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  date = {2019-02},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  shortjournal = {J. R. Stat. Soc. A},
  volume = {182},
  number = {2},
  eprint = {1709.01449},
  eprinttype = {arXiv},
  eprintclass = {stat},
  pages = {389--402},
  issn = {0964-1998, 1467-985X},
  doi = {10.1111/rssa.12378},
  url = {http://arxiv.org/abs/1709.01449},
  urldate = {2023-01-11},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high-dimensional models that are used by applied researchers.},
  langid = {english},
  keywords = {bayesian,priors,Statistics - Applications,Statistics - Methodology,visualization,workflow},
  file = {C:\Users\Driver\Zotero\storage\LURQX2ZE\Gabry et al. - 2019 - Visualization in Bayesian workflow.pdf}
}

@article{hoffman2022catching,
  title = {Catching {{Up}} on {{Multilevel Modeling}}},
  author = {Hoffman, Lesa and Walters, Ryan W.},
  date = {2022-01-04},
  journaltitle = {Annual Review of Psychology},
  shortjournal = {Annu. Rev. Psychol.},
  volume = {73},
  number = {1},
  pages = {659--689},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-020821-103525},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-psych-020821-103525},
  urldate = {2022-02-18},
  abstract = {This review focuses on the use of multilevel models in psychology and other social sciences. We target readers who are catching up on current best practices and sources of controversy in the specification of multilevel models. We first describe common use cases for clustered, longitudinal, and cross-classified designs, as well as their combinations. Using examples from both clustered and longitudinal designs, we then address issues of centering for observed predictor variables: its use in creating interpretable fixed and random effects of predictors, its relationship to endogeneity problems (correlations between predictors and model error terms), and its translation into multivariate multilevel models (using latent-centering within multilevel structural equation models). Finally, we describe novel extensions—mixedeffects location–scale models—designed for predicting differential amounts of variability.},
  langid = {english},
  keywords = {mlm,multilevel,primer},
  file = {C:\Users\Driver\Zotero\storage\MYT6BW22\Hoffman and Walters - 2022 - Catching Up on Multilevel Modeling.pdf}
}

@article{neale2016openmx,
  title = {{{OpenMx}} 2.0: Extended Structural Equation and Statistical Modeling},
  shorttitle = {Openmx 2.0},
  author = {Neale, Michael C. and Hunter, Michael D. and Pritikin, Joshua N. and Zahery, Mahsa and Brick, Timothy R. and Kirkpatrick, Robert M. and Estabrook, Ryne and Bates, Timothy C. and Maes, Hermine H. and Boker, Steven M.},
  date = {2016-06-01},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {81},
  number = {2},
  pages = {535--549},
  issn = {1860-0980},
  doi = {10.1007/s11336-014-9435-8},
  url = {https://doi.org/10.1007/s11336-014-9435-8},
  urldate = {2023-12-04},
  abstract = {The new software package OpenMx~2.0 for structural equation and other statistical modeling is introduced and its features are described. OpenMx is evolving in a modular direction and now allows a mix-and-match computational approach that separates model expectations from fit functions and optimizers. Major backend architectural improvements include a move to swappable open-source optimizers such as the newly written CSOLNP. Entire new methodologies such as item factor analysis and state space modeling have been implemented. New model expectation functions including support for the expression of models in LISREL syntax and a simplified multigroup expectation function are available. Ease-of-use improvements include helper functions to standardize model parameters and compute their Jacobian-based standard errors, access to model components through standard R \$ mechanisms, and improved tab completion from within the R Graphical User Interface.},
  langid = {english},
  keywords = {and Law,Assessment,Assessment Testing and Evaluation,behavior genetics,Behavorial Science,big data,Education,full information maximum likelihood,item factor analysis,latent class analysis,mixture distribution,optimization,ordinal data,path analysis,Path Analysis,Psychometrics,Public Policy,state space modeling,State space modeling,Statistical Theory and Methods,Statistics for Social Science,Statistics for Social Science Behavorial Science Education Public Policy and Law,structural equation modeling,Structural equation modeling,substance use data analysis,Testing and Evaluation,time series},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\A4LBE4K7\\Neale et al_2016_OpenMx 2.pdf;C\:\\Users\\Driver\\Zotero\\storage\\SY6INJXZ\\Neale et al_2016_OpenMx 2.pdf;C\:\\Users\\Driver\\Zotero\\storage\\88ERNZEV\\10.html}
}

@incollection{oud2018first,
  title = {First- and Higher-Order Continuous Time Models for Arbitrary n Using Sem},
  booktitle = {Continuous Time Modeling in the Behavioral and Related Sciences},
  author = {Oud, Johan H. L. and Voelkle, Manuel C. and Driver, Charles C.},
  editor = {family=Montfort, given=Kees, prefix=van, useprefix=true and Oud, Johan H.L. and Voelkle, Manuel C.},
  date = {2018},
  pages = {1--26},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-77219-6_1},
  url = {https://doi.org/10.1007/978-3-319-77219-6_1},
  urldate = {2019-03-28},
  abstract = {In this chapter we review continuous time series modeling and estimation by extended structural equation models (SEM) for single subjects and N {$>$} 1. First-order as well as higher-order models will be dealt with. Both will be handled by the general state space approach which reformulates higher-order models as first-order models. In addition to the basic model, the extensions of exogenous variables and traits (random intercepts) will be introduced. The connection between continuous time and discrete time for estimating the model by SEM will be made by the exact discrete model (EDM). It is by the EDM that the exact estimation procedure in this chapter differentiates from many approximate procedures found in the literature. The proposed analysis procedure will be applied to the well-known Wolfer sunspot data, an N = 1 time series that has been analyzed by several continuous time analysts in the past. The analysis will be carried out by ctsem, an R-package for continuous time modeling that interfaces to OpenMx, and the results will be compared to those reported in the previous studies.},
  isbn = {978-3-319-77219-6},
  langid = {english}
}

@article{yarkoni2017choosing,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  author = {Yarkoni, Tal and Westfall, Jacob},
  date = {2017-11-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691617693393},
  url = {https://doi.org/10.1177/1745691617693393},
  urldate = {2025-03-10},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology’s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  langid = {english},
  file = {C:\Users\Driver\Zotero\storage\9U5TU52C\Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology Lessons From Machine Learning.pdf}
}
