@article{aalen2016can,
  title = {Can We Believe the {{DAGs}}? {{A}} Comment on the Relationship between Causal {{DAGs}} and Mechanisms},
  author = {Aalen, Odd Olai and Røysland, Kjetil and Gran, Jon Michael and Kouyos, Roger and Lange, Tanja},
  date = {2016},
  journaltitle = {Statistical Methods in Medical Research},
  volume = {25},
  number = {5},
  pages = {2294--2314},
  publisher = {SAGE Publications Sage UK: London, England},
  doi = {10.1177/0962280213520436}
}

@article{asparouhov2018dynamica,
  title = {Dynamic {{Structural Equation Models}}},
  author = {Asparouhov, Tihomir and Hamaker, Ellen L. and Muthén, Bengt},
  date = {2018-05-04},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {25},
  number = {3},
  pages = {359--388},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2017.1406803},
  abstract = {This article presents dynamic structural equation modeling (DSEM), which can be used to study the evolution of observed and latent variables as well as the structural equation models over time. DSEM is suitable for analyzing intensive longitudinal data where observations from multiple individuals are collected at many points in time. The modeling framework encompasses previously published DSEM models and is a comprehensive attempt to combine time-series modeling with structural equation modeling. DSEM is estimated with Bayesian methods using the Markov chain Monte Carlo Gibbs sampler and the Metropolis–Hastings sampler. We provide a detailed description of the estimation algorithm as implemented in the Mplus software package. DSEM can be used for longitudinal analysis of any duration and with any number of observations across time. Simulation studies are used to illustrate the framework and study the performance of the estimation method. Methods for evaluating model fit are also discussed.},
  keywords = {Baysian methods,dynamic factor analysis,intensive longitudinal data,time series analysis},
  file = {C:\Users\Driver\Zotero\storage\7GCNFUJR\Asparouhov et al. - 2018 - Dynamic Structural Equation Models.pdf}
}

@article{bates2015fitting,
  title = {Fitting Linear Mixed-Effects Models Using {{lme4}}},
  author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01}
}

@article{bender2023instructing,
  title = {Instructing Use of an Effective Strategy Improves Recognition Memory in Healthy Adults},
  author = {Bender, Andrew R. and Driver, Charles C. and Hertzog, Christopher and Raz, Naftali},
  date = {2023-03-04},
  journaltitle = {The Journals of Gerontology. Series B, Psychological Sciences and Social Sciences},
  shortjournal = {J Gerontol B Psychol Sci Soc Sci},
  volume = {78},
  number = {3},
  eprint = {36130328},
  eprinttype = {pubmed},
  pages = {383--393},
  issn = {1758-5368},
  doi = {10.1093/geronb/gbac144},
  abstract = {OBJECTIVES: Age-related memory decrements correlate with metacognitive declines, including knowledge and deployment of effective mnemonic encoding strategies. However, whether imparting such strategy suffices for mitigating memory differences is unclear. METHOD: In a longitudinal study of 276 healthy adults aged 18-79 years, we tested associative and working memory, and assessed beliefs regarding mnemonic strategies. Testing was repeated every 2 years, 5 times. Starting with the third occasion, we instructed participants to use an effective mnemonic strategy (sentence generation). Using continuous-time dynamic modeling, we assessed changes in the item and associative recognition, intervention effects, and their relations with age, sex, meta-memory beliefs, working memory, and metabolic health. RESULTS: Younger age, better working memory, and stronger belief in effective mnemonic strategies predicted better recognition, whereas instructional intervention attenuated associative memory deficits, with some persistence over time. DISCUSSION: The present findings show merely imparting effective strategies holds promise for mitigating age-related associative memory deficits.},
  langid = {english},
  pmcid = {PMC9985315},
  keywords = {Aging,Association Learning,Humans,Intervention,Longitudinal Studies,Memory,Memory Disorders,Memory Short-Term,Metabolic risk,Metacognition,Strategy}
}

@article{berry2017practical,
  title = {On the Practical Interpretability of Cross-Lagged Panel Models: Rethinking a Developmental Workhorse},
  shorttitle = {On the Practical Interpretability of Cross-Lagged Panel Models},
  author = {Berry, Daniel and Willoughby, Michael T.},
  date = {2017},
  journaltitle = {Child Development},
  volume = {88},
  number = {4},
  pages = {1186--1206},
  issn = {1467-8624},
  doi = {10.1111/cdev.12660},
  abstract = {Reciprocal feedback processes between experience and development are central to contemporary developmental theory. Autoregressive cross-lagged panel (ARCL) models represent a common analytic approach intended to test such dynamics. The authors demonstrate that—despite the ARCL model's intuitive appeal—it typically (a) fails to align with the theoretical processes that it is intended to test and (b) yields estimates that are difficult to interpret meaningfully. Specifically, using a Monte Carlo simulation and two empirical examples concerning the reciprocal relation between spanking and child aggression, it is shown that the cross-lagged estimates derived from the ARCL model reflect a weighted—and typically uninterpretable—amalgam of between- and within-person associations. The authors highlight one readily implemented respecification that better addresses these multiple levels of inference.},
  langid = {english},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\LDHW2L6N\\Berry and Willoughby - 2017 - On the Practical Interpretability of Cross-Lagged Panel Models Rethinking a Developmental Workhorse.pdf;C\:\\Users\\Driver\\Zotero\\storage\\H4A22TLA\\cdev.html}
}

@article{boker2024separating,
  title = {Separating {{Long-Term Equilibrium Adaptation}} from {{Short-Term Self-Regulation Dynamics Using Latent Differential Equations}}},
  author = {Boker, Steven M. and Daniel, Katharine E. and Orzek, Jannik},
  date = {2024-11-01},
  journaltitle = {Multivariate Behavioral Research},
  volume = {59},
  number = {6},
  eprint = {37624870},
  eprinttype = {pubmed},
  pages = {1177--1187},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1080/00273171.2023.2228302},
  abstract = {Self-regulating systems change along different timescales. Within a given week, a depressed person’s affect might oscillate around a low equilibrium point. However, when the timeframe is expanded to capture the year during which they onboarded antidepressant medication, their equilibrium and oscillatory patterns might reorganize around a higher affective point. To simultaneously account for the meaningful change processes that happen at different time scales in complex self-regulatory systems, we propose a single model that combines a second-order linear differential equation for short timescale regulation and a first-order linear differential equation for long timescale adaptation of equilibrium. This model allows for individual-level moderation of short-timescale model parameters. The model is tested in a simulation study which shows that, surprisingly, the short and long timescales can fully overlap and the model still converges to the reasonable estimates. Finally, an application of this model to self-regulation of emotional well-being in recent widows is presented and discussed.},
  keywords = {emotional well-being,Equilibrium dynamics,latent differential equations,multi-timescale analysis},
  file = {C:\Users\Driver\Zotero\storage\IAI6FCNW\Boker et al. - 2024 - Separating Long-Term Equilibrium Adaptation from Short-Term Self-Regulation Dynamics Using Latent Di.pdf}
}

@article{borsboom2021theory,
  title = {Theory Construction Methodology: A Practical Framework for Building Theories in Psychology},
  shorttitle = {Theory Construction Methodology},
  author = {Borsboom, Denny and family=Maas, given=Han L. J., prefix=van der, useprefix=true and Dalege, Jonas and Kievit, Rogier A. and Haig, Brian D.},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {756--766},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620969647},
  abstract = {This article aims to improve theory formation in psychology by developing a practical methodology for constructing explanatory theories: theory construction methodology (TCM). TCM is a sequence of five steps. First, the theorist identifies a domain of empirical phenomena that becomes the target of explanation. Second, the theorist constructs a prototheory, a set of theoretical principles that putatively explain these phenomena. Third, the prototheory is used to construct a formal model, a set of model equations that encode explanatory principles. Fourth, the theorist investigates the explanatory adequacy of the model by formalizing its empirical phenomena and assessing whether it indeed reproduces these phenomena. Fifth, the theorist studies the overall adequacy of the theory by evaluating whether the identified phenomena are indeed reproduced faithfully and whether the explanatory principles are sufficiently parsimonious and substantively plausible. We explain TCM with an example taken from research on intelligence (the mutualism model of intelligence), in which key elements of the method have been successfully implemented. We discuss the place of TCM in the larger scheme of scientific research and propose an outline for a university curriculum that can systematically educate psychologists in the process of theory formation.},
  langid = {english},
  file = {C:\Users\Driver\Zotero\storage\T6F34KL9\Borsboom et al. - 2021 - Theory Construction Methodology A Practical Framework for Building Theories in Psychology.pdf}
}

@article{borsboom2024integrating,
  title = {Integrating {{Intra-}} and {{Interindividual Phenomena}} in {{Psychological Theories}}},
  author = {Borsboom, Denny and Haslbeck, Jonas},
  date = {2024-11-01},
  journaltitle = {Multivariate Behavioral Research},
  volume = {59},
  number = {6},
  eprint = {38989982},
  eprinttype = {pubmed},
  pages = {1290--1309},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1080/00273171.2024.2336178},
  abstract = {Psychological science is divided into two distinct methodological traditions. One tradition seeks to understand how people function at the individual level, while the other seeks to understand how people differ from each other. Methodologies that have grown out of these traditions typically rely on different sources of data. While both use statistical models to understand the structure of the data, and these models are often similar, Molenaar (2004) showed that results from one type of analysis rarely transfer to the other, unless unrealistic assumptions hold. This raises the question how we may integrate these approaches. In this paper, we argue that formalized theories can be used to connect intra- and interindividual levels of analysis. This connection is indirect, in the sense that the relationship between theory and data is best understood through the intermediate level of phenomena: robust statistical patterns in empirical data. To illustrate this, we introduce a distinction between intra- and interindividual phenomena, and argue that many psychological theories will have implications for both types of phenomena. Formalization provides us with a methodological tool for investigating what kinds of intra- and interindividual phenomena we should expect to find if the theory under consideration were true.},
  keywords = {ergodicity,formal theory,Individual differences,intra-individual processes},
  file = {C:\Users\Driver\Zotero\storage\FMBWN2TM\Borsboom and Haslbeck - 2024 - Integrating Intra- and Interindividual Phenomena in Psychological Theories.pdf}
}

@incollection{brandmaier2018Recursive,
  title = {Recursive Partitioning in Continuous Time Analysis},
  booktitle = {Continuous {{Time Modeling}} in the {{Behavioral}} and {{Related Sciences}}},
  author = {Brandmaier, Andreas M. and Driver, Charles C. and Voelkle, Manuel C.},
  editor = {family=Montfort, given=Kees, prefix=van, useprefix=true and Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2018},
  pages = {259--282},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-77219-6_11},
  abstract = {Building models fully informed by theory is challenging when data sets are large and strong assumptions about all variables of interest and their interrelations cannot be made. Machine learning-inspired approaches have been gaining momentum in modeling such “big” data because they offer a systematic approach to searching for potential interrelationships among variables. In practice, researchers may often start with a small model strongly guided by theory. In a second step, however, they quickly face the challenge of selecting among additional variables as to whether they should be included in or omitted from the model. This situation calls for both a confirmatory statistical modeling approach and an exploratory statistical learning approach to data analysis within a single framework. Structural equation model (SEM) trees, a combination of SEM and decision trees (also known as classification and regression trees), offer a principled solution to this selection problem. SEM trees hierarchically split empirical data into homogeneous groups sharing similar data patterns by recursively selecting optimal predictors of these differences from a potentially large set of candidate variables. SEM forests are an extension of SEM trees, consisting of ensembles of SEM trees, each built on a random sample of the original data. By aggregating over ensembles of SEM trees (SEM forests), we obtain measures of variable importance that are more robust than measures from single trees. In the present chapter, we combine SEM trees and SEM-based continuous time modeling. The resulting approach of continuous time SEM trees will be illustrated by exploring dynamics in perceptual speed using data from the COGITO study.},
  isbn = {978-3-319-77219-6},
  langid = {english},
  file = {C:\Users\Driver\Dropbox\MPIB\zotero\charlie\Brandmaier et al_2018_Recursive Partitioning in Continuous Time Analysis.pdf}
}

@article{butler2013emotional,
  title = {Emotional Coregulation in Close Relationships},
  author = {Butler, Emily A. and Randall, Ashley K.},
  date = {2013-04-01},
  journaltitle = {Emotion Review},
  volume = {5},
  number = {2},
  pages = {202--210},
  publisher = {SAGE Publications},
  issn = {1754-0739},
  doi = {10.1177/1754073912451630},
  abstract = {Coregulation refers to the process by which relationship partners form a dyadic emotional system involving an oscillating pattern of affective arousal and dampening that dynamically maintains an optimal emotional state. Coregulation may represent an important form of interpersonal emotion regulation, but confusion exists in the literature due to a lack of precision in the usage of the term. We propose an operational definition for coregulation as a bidirectional linkage of oscillating emotional channels between partners, which contributes to emotional stability for both partners. We propose several distinctions and raise unanswered questions that will need to be addressed in order to understand the relevance of coregulation for well-being in adulthood.},
  langid = {english},
  file = {C:\Users\Driver\Zotero\storage\7A4AI7WR\Butler and Randall - 2013 - Emotional Coregulation in Close Relationships.pdf}
}

@article{carpenter2017stan,
  title = {Stan: A Probabilistic Programming Language},
  shorttitle = {\mkbibemph{Stan}},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {76},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  langid = {english},
  keywords = {algorithmic differentiation,Bayesian inference,probabilistic programming,Stan},
  file = {C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\heirarchical ct article\\Carpenter et al_2017_Stan.pdf;C\:\\Users\\Driver\\Zotero\\storage\\CGJNAJKA\\v076i01.html}
}

@manual{ctsemCRAN,
  type = {manual},
  title = {Ctsem: {{Continuous}} Time Structural Equation Modelling},
  author = {Driver, Charles C. and Voelkle, Manuel C. and Oud, Johan H. L.},
  date = {2025},
  publisher = {CRAN},
  url = {https://cran.r-project.org/package=ctsem}
}

@article{curran2010twelve,
  title = {Twelve Frequently Asked Questions about Growth Curve Modeling},
  author = {Curran, Patrick J. and Obeidat, Khawla and Losardo, Diane},
  date = {2010-04-30},
  journaltitle = {Journal of Cognition and Development},
  volume = {11},
  number = {2},
  eprint = {21743795},
  eprinttype = {pubmed},
  pages = {121--136},
  publisher = {Routledge},
  issn = {1524-8372},
  doi = {10.1080/15248371003699969},
  abstract = {Longitudinal data analysis has long played a significant role in empirical research within the developmental sciences. The past decade has given rise to a host of new and exciting analytic methods for studying between-person differences in within-person change. These methods are broadly organized under the term growth curve models. The historical lines of development leading to current growth models span multiple disciplines within both the social and statistical sciences, and this in turn makes it challenging for developmental researchers to gain a broader understanding of the current state of this literature. To help address this challenge, the authors pose 12 questions that frequently arise in growth curve modeling, particularly in applications within developmental psychology. They provide concise and nontechnical responses to each question and make specific recommendations for further readings.},
  file = {C:\Users\Driver\Zotero\storage\F5SZL77Y\Curran et al. - 2010 - Twelve Frequently Asked Questions About Growth Curve Modeling.pdf}
}

@article{driver2017continuous,
  title = {Continuous {{Time Structural Equation Modeling}} with {{R}} Package Ctsem},
  author = {Driver, Charles C. and Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {77},
  number = {5},
  pages = {1--35},
  issn = {1548-7660},
  doi = {10.18637/jss.v077.i05},
  abstract = {We introduce ctsem, an R package for continuous time structural equation modeling of panel (N ¿ 1) and time series (N = 1) data, using full information maximum likelihood. Most dynamic models (e.g., cross-lagged panel models) in the social and behavioural sciences are discrete time models. An assumption of discrete time models is that time intervals between measurements are equal, and that all subjects were assessed at the same intervals. Violations of this assumption are often ignored due to the difficulty of accounting for varying time intervals, therefore parameter estimates can be biased and the time course of effects becomes ambiguous. By using stochastic differential equations to estimate an underlying continuous process, continuous time models allow for any pattern of measurement occasions. By interfacing to OpenMx, ctsem combines the flexible specification of structural equation models with the enhanced data gathering opportunities and improved estimation of continuous time models. ctsem can estimate relationships over time for multiple latent processes, measured by multiple noisy indicators with varying time intervals between observations. Within and between effects are estimated simultaneously by modeling both observed covariates and unobserved heterogeneity. Exogenous shocks with different shapes, group differences, higher order diffusion effects and oscillating processes can all be simply modeled. We first introduce and define continuous time models, then show how to specify and estimate a range of continuous time models using ctsem.},
  keywords = {continuous time,dynamic models,Dynamic models,Kalman filter,longitudinal modeling,Longitudinal modeling,panel data,Panel data,R,state space,stochastic differential equation,structural equation modeling,time series},
  file = {C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\Driver et al_2017_Continuous time structural equation modeling with r package ctsem.pdf;C\:\\Users\\Driver\\Zotero\\storage\\LQLGLHWW\\Driver et al_2017_Continuous time structural equation modeling with r package ctsem.pdf}
}

@article{Driver2018CTBayes,
  title = {Hierarchical {{Bayesian}} Continuous Time Dynamic Modeling},
  author = {Driver, Charles C. and Voelkle, Manuel C.},
  date = {2018},
  journaltitle = {Psychological Methods},
  volume = {23},
  number = {4},
  pages = {774--799},
  doi = {10.1037/met0000168}
}

@article{driver2018hierarchicala,
  title = {Hierarchical {{Bayesian}} Continuous Time Dynamic Modeling},
  author = {Driver, Charles C and Voelkle, Manuel C},
  date = {2018},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychol Methods},
  volume = {23},
  number = {4},
  pages = {774--799},
  publisher = {American Psychological Association},
  doi = {10.1037/met0000168},
  keywords = {Bayes Theorem,Humans,Individuality,Models Psychological,Models Statistical,Psychology}
}

@incollection{driver2018understanding,
  title = {Understanding the Time Course of Interventions with Continuous Time Dynamic Models},
  booktitle = {Continuous Time Modeling in the Behavioral and Related Sciences},
  author = {Driver, Charles C. and Voelkle, Manuel C.},
  editor = {family=Montfort, given=Kees, prefix=van, useprefix=false and Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2018},
  pages = {79--109},
  publisher = {Springer International Publishing},
  location = {New York},
  url = {//www.springer.com/de/book/9783319772189},
  isbn = {978-3-319-77218-9},
  file = {C:\Users\Driver\Dropbox\MPIB\zotero\Driver_Voelkle_2018_Understanding the Time Course of Interventions with Continuous Time Dynamic.pdf}
}

@article{driver2021computational,
  title = {Computational Efficiency in Continuous (and Discrete!) Time Models – Comment on {{Hecht}} and {{Zitzmann}}},
  author = {Driver, Charles C},
  date = {2021-02-04},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {28},
  number = {5},
  pages = {791--793},
  issn = {1070-5511},
  doi = {10.1080/10705511.2021.1877547},
  abstract = {Continuous-time models generally imply a stochastic differential equation for latent processes, coupled to a measurement model. Various computational issues can arise, and there are different estimation approaches, with different trade-offs. It has been claimed that a SEM style continuous-time model can reduce run times for Bayesian estimations of continuous-time models from hours to minutes. However this claim is not true in the general case, but requires that individuals are characterized by the same covariance and means structure, and that the number of time points is not large. While such simplifications can be valuable, and indeed are in use in existing software when appropriate, they are in general quite restrictive. The hierarchical Bayesian form of ctsem was, for instance, developed precisely to estimate models where these restrictions do not hold. To try to shed some more light on these aspects, I discuss the related issues herein.},
  keywords = {Continuous time,state space,stochastic differential equation},
  file = {C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\charlie\\Driver_2021_Computational efficiency in continuous (and Discrete.pdf;C\:\\Users\\Driver\\Zotero\\storage\\7HPVW4MZ\\Driver_2021_Computational efficiency in continuous (and Discrete.pdf;C\:\\Users\\Driver\\Zotero\\storage\\WXRE7Z8H\\Driver - 2021 - Computational Efficiency in Continuous (and Discre.pdf;C\:\\Users\\Driver\\Zotero\\storage\\XFXGRXAT\\10705511.2021.html}
}

@incollection{driver2021hierarchical,
  title = {Hierarchical Continuous Time Modeling},
  booktitle = {The Handbook of Personality Dynamics and Processes},
  author = {Driver, Charles C. and Voelkle, Manuel C.},
  editor = {Rauthmann, John F.},
  date = {2021},
  pages = {887--908},
  publisher = {Academic Press},
  url = {https://doi.org/10.1016/B978-0-12-813995-0.00034-0},
  abstract = {We describe the basic usage of the hierarchical formulation of the ctsem software for continuous-time dynamic modeling in R, the scope of which been expanded to include nonlinear models and optimization with optional importance sampling, meaning that the approach described herein largely supersedes the initial mixed effects approach based upon OpenMx, as estimation options now include maximum likelihood, maximum a posteriori, and fully Bayesian. We describe the continuous time dynamic model governing within-subject dynamics, and the hierarchical model governing the distribution of subject-level parameters, then walk through installing the ctsem software, setting up a data structure, specifying and fitting the model, followed by summary and plotting functions. Some details on additional complexity are then provided, including an example model with a more complex dynamic structure, a discussion of the various options for incorporating stationarity assumptions into the model, and a walk-through of the various transformations involved in the model.},
  isbn = {978-0-12-813995-0},
  langid = {english},
  keywords = {Drift,Matrix,Model,Parameter,Population,Prior,Standard,Time},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\4R9NT7D5\\B9780128139950000340.html;C\:\\Users\\Driver\\Zotero\\storage\\RHVMTAW5\\B9780128139950000340.html}
}

@article{driver2023formalizing,
  title = {Formalizing Developmental Phenomena as Continuous-Time Systems: {{Relations}} between Mathematics and Language Development},
  shorttitle = {Formalizing Developmental Phenomena as Continuous-Time Systems},
  author = {Driver, Charles C. and Tomasik, Martin J.},
  date = {2023},
  journaltitle = {Child Development},
  volume = {94},
  number = {6},
  pages = {1454--1471},
  issn = {1467-8624},
  doi = {10.1111/cdev.13990},
  abstract = {We demonstrate how developmental theories may be instantiated as statistical models, using hierarchical continuous-time dynamic systems. This approach offers a flexible specification and an often more direct link between theory and model parameters than common modeling frameworks. We address developmental theories of the relation between the academic competencies of mathematics and language, using data from the online learning system Mindsteps. We use ability estimates from 160,164 observation occasions, across N = 4623 3rd to 9th grade students and five ability domains. Model development is step-by-step from simple to complex, with ramifications for theory and modeling discussed at each step.},
  langid = {english},
  file = {C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\charlie\\Driver_Tomasik_Formalizing developmental phenomena as continuous-time systems.pdf;C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\crosslagged\\Driver_Tomasik_2023_Formalizing developmental phenomena as continuous-time systems.pdf;C\:\\Users\\Driver\\Zotero\\storage\\6V9P4YQR\\Driver_Tomasik_2023_Formalizing developmental phenomena as continuous-time systems.pdf;C\:\\Users\\Driver\\Zotero\\storage\\7QE62QJU\\Driver_Tomasik_Formalizing developmental phenomena as continuous-time systems.pdf;C\:\\Users\\Driver\\Zotero\\storage\\4GEEAHDX\\cdev.html}
}

@article{driver2025inference,
  title = {Inference with Cross-Lagged Effects—{{Problems}} in Time},
  author = {Driver, Charles C.},
  date = {2025},
  journaltitle = {Psychological Methods},
  volume = {30},
  number = {1},
  pages = {174--202},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/met0000665},
  abstract = {The interpretation of cross-effects from vector autoregressive models to infer structure and causality among constructs is widespread and sometimes problematic. I describe problems in the interpretation of cross-effects when processes that are thought to fluctuate continuously in time are, as is typically done, modeled as changing only in discrete steps (as in e.g., structural equation modeling)—zeroes in a discrete-time temporal matrix do not necessarily correspond to zero effects in the underlying continuous processes, and vice versa. This has implications for the common case when the presence or absence of cross-effects is used for inference about underlying causal processes. I demonstrate these problems via simulation, and also show that when an underlying set of processes are continuous in time, even relatively few direct causal links can result in much denser temporal effect matrices in discrete-time. I demonstrate one solution to these issues, namely parameterizing the system as a stochastic differential equation and focusing inference on the continuous-time temporal effects. I follow this with some discussion of issues regarding the switch to continuous-time, specifically regularization, appropriate measurement time lag, and model order. An empirical example using intensive longitudinal data highlights some of the complexities of applying such approaches to real data, particularly with respect to model specification, examining misspecification, and parameter interpretation. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  keywords = {Inference,Statistical Data,Statistical Inference,Stochastic Modeling,Time Series},
  file = {C:\Users\Driver\Zotero\storage\E4BE5DJH\Driver - 2025 - Inference with cross-lagged effects—Problems in time.pdf}
}

@book{DurbinKoopman2012,
  title = {Time Series Analysis by State Space Methods},
  author = {Durbin, James and Koopman, Siem Jan},
  date = {2012},
  edition = {2},
  publisher = {Oxford University Press},
  location = {Oxford},
  isbn = {978-0-19-964117-8}
}

@article{epskamp2020psychometrica,
  title = {Psychometric Network Models from Time-Series and Panel Data},
  author = {Epskamp, Sacha},
  date = {2020-03},
  journaltitle = {Psychometrika},
  volume = {85},
  number = {1},
  pages = {206--231},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-020-09697-3},
  abstract = {Researchers in the field of network psychometrics often focus on the estimation of Gaussian graphical models (GGMs)—an undirected network model of partial correlations—between observed variables of cross-sectional data or single-subject time-series data. This assumes that all variables are measured without measurement error, which may be implausible. In addition, cross-sectional data cannot distinguish between within-subject and between-subject effects. This paper provides a general framework that extends GGM modeling with latent variables, including relationships over time. These relationships can be estimated from time-series data or panel data featuring at least three waves of measurement. The model takes the form of a graphical vector-autoregression model between latent variables and is termed the ts-lvgvar when estimated from time-series data and the panel-lvgvar when estimated from panel data. These methods have been implemented in the software package psychonetrics, which is exemplified in two empirical examples, one using time-series data and one using panel data, and evaluated in two large-scale simulation studies. The paper concludes with a discussion on ergodicity and generalizability. Although within-subject effects may in principle be separated from between-subject effects, the interpretation of these results rests on the intensity and the time interval of measurement and on the plausibility of the assumption of stationarity.},
  langid = {english},
  keywords = {dynamics,Gaussian graphical model,network psychometrics,panel data,structural equation modeling,time-series data},
  file = {C:\Users\Driver\Zotero\storage\AXHBSZDB\Epskamp - 2020 - Psychometric Network Models from Time-Series and Panel Data.pdf}
}

@article{Gabry2019BayesVis,
  title = {Visualization in Bayesian Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  date = {2019},
  journaltitle = {Journal of the Royal Statistical Society: Series A},
  volume = {182},
  number = {2},
  pages = {389--402},
  doi = {10.1111/rssa.12378}
}

@article{Gelman1996PPC,
  title = {Posterior Predictive Assessment of Model Fitness via Realized Discrepancies},
  author = {Gelman, Andrew and Meng, Xiao-Li and Stern, Hal},
  date = {1996},
  journaltitle = {Statistica Sinica},
  volume = {6},
  number = {4},
  eprint = {24306036},
  eprinttype = {jstor},
  pages = {733--760},
  publisher = {Institute of Statistical Science, Academia Sinica},
  issn = {1017-0405},
  url = {https://www.jstor.org/stable/24306036},
  urldate = {2025-08-22},
  abstract = {This paper considers Bayesian counterparts of the classical tests for goodness of fit and their use in judging the fit of a single Bayesian model to the observed data. We focus on posterior predictive assessment, in a framework that also includes conditioning on auxiliary statistics. The Bayesian formulation facilitates the construction and calculation of a meaningful reference distribution not only for any (classical) statistic, but also for any parameter-dependent "statistic" or discrepancy. The latter allows us to propose the realized discrepancy assessment of model fitness, which directly measures the true discrepancy between data and the posited model, for any aspect of the model which we want to explore. The computation required for the realized discrepancy assessment is a straightforward byproduct of the posterior simulation used for the original Bayesian analysis. We illustrate with three applied examples. The first example, which serves mainly to motivate the work, illustrates the difficulty of classical tests in assessing the fitness of a Poisson model to a positron emission tomography image that is constrained to be nonnegative. The second and third examples illustrate the details of the posterior predictive approach in two problems: estimation in a model with inequality constraints on the parameters, and estimation in a mixture model. In all three examples, standard test statistics (either a χ2 or a likelihood ratio) are not pivotal: the difficulty is not just how to compute the reference distribution for the test, but that in the classical framework no such distribution exists, independent of the unknown model parameters.},
  file = {C:\Users\Driver\Zotero\storage\PDP3CQPW\Gelman et al. - 1996 - Posterior Predictive Assessment of Model Fitness Via Realized Discrepancies.pdf}
}

@article{hamaker2015critiquea,
  title = {A Critique of the Cross-Lagged Panel Model},
  author = {Hamaker, Ellen L. and Kuiper, Rebecca M. and Grasman, Raoul P. P. P.},
  date = {2015},
  journaltitle = {Psychological Methods},
  volume = {20},
  number = {1},
  pages = {102--116},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/a0038889},
  abstract = {The cross-lagged panel model (CLPM) is believed by many to overcome the problems associated with the use of cross-lagged correlations as a way to study causal influences in longitudinal panel data. The current article, however, shows that if stability of constructs is to some extent of a trait-like, time-invariant nature, the autoregressive relationships of the CLPM fail to adequately account for this. As a result, the lagged parameters that are obtained with the CLPM do not represent the actual within-person relationships over time, and this may lead to erroneous conclusions regarding the presence, predominance, and sign of causal influences. In this article we present an alternative model that separates the within-person process from stable between-person differences through the inclusion of random intercepts, and we discuss how this model is related to existing structural equation models that include cross-lagged relationships. We derive the analytical relationship between the cross-lagged parameters from the CLPM and the alternative model, and use simulations to demonstrate the spurious results that may arise when using the CLPM to analyze data that include stable, trait-like individual differences. We also present a modeling strategy to avoid this pitfall and illustrate this using an empirical data set. The implications for both existing and future cross-lagged panel research are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Longitudinal Studies,Models,Repeated Measures,Structural Equation Modeling},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\2CZA5JBT\\Hamaker et al. - 2015 - A critique of the cross-lagged panel model.pdf;C\:\\Users\\Driver\\Zotero\\storage\\2NFHUQTX\\2015-13154-004.html}
}

@book{Harvey1989,
  title = {Forecasting, Structural Time Series Models and the Kalman Filter},
  author = {Harvey, Andrew C.},
  date = {1989},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  isbn = {978-0-521-32196-9}
}

@article{haslbeck2022modeling,
  title = {Modeling Psychopathology: {{From}} Data Models to Formal Theories},
  shorttitle = {Modeling Psychopathology},
  author = {Haslbeck, Jonas M. B. and Ryan, Oisín and Robinaugh, Donald J. and Waldorp, Lourens J. and Borsboom, Denny},
  date = {2022},
  journaltitle = {Psychological Methods},
  volume = {27},
  number = {6},
  pages = {930--957},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/met0000303},
  abstract = {Over the past decade, there has been a surge of empirical research investigating mental disorders as complex systems. In this article, we investigate how to best make use of this growing body of empirical research and move the field toward its fundamental aims of explaining, predicting, and controlling psychopathology. We first review the contemporary philosophy of science literature on scientific theories and argue that fully achieving the aims of explanation, prediction, and control requires that we construct formal theories of mental disorders: theories expressed in the language of mathematics or a computational programming language. We then investigate three routes by which one can use empirical findings (i.e., data models) to construct formal theories: (a) using data models themselves as formal theories, (b) using data models to infer formal theories, and (c) comparing empirical data models to theory-implied data models in order to evaluate and refine an existing formal theory. We argue that the third approach is the most promising path forward. We conclude by introducing the abductive formal theory construction (AFTC) framework, informed by both our review of philosophy of science and our methodological investigation. We argue that this approach provides a clear and promising way forward for using empirical research to inform the generation, development, and testing of formal theories both in the domain of psychopathology and in the broader field of psychological science. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Computational Modeling,Data Sets,Models,Philosophies,Psychopathology,Sciences,Simulation,Theories,Theory Formulation},
  file = {C:\Users\Driver\Zotero\storage\H7BTYTNZ\Haslbeck et al. - 2022 - Modeling psychopathology From data models to formal theories.pdf}
}

@article{Higham2001,
  title = {An Algorithmic Introduction to Numerical Simulation of Stochastic Differential Equations},
  author = {Higham, Desmond J.},
  date = {2001},
  journaltitle = {SIAM Review},
  volume = {43},
  number = {3},
  pages = {525--546},
  doi = {10.1137/S0036144500378302}
}

@article{Kalman1960,
  title = {A New Approach to Linear Filtering and Prediction Problems},
  author = {Kalman, Rudolph E.},
  date = {1960},
  journaltitle = {Journal of Basic Engineering},
  volume = {82},
  number = {1},
  pages = {35--45},
  doi = {10.1115/1.3662552}
}

@incollection{kenny2005crosslagged,
  title = {Cross-{{Lagged Panel Design}}},
  booktitle = {Encyclopedia of {{Statistics}} in {{Behavioral Science}}},
  author = {Kenny, David A.},
  date = {2005},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/0470013192.bsa156},
  abstract = {The minimal cross-lagged panel design is two variables measured at two times. Multiple regression analyses, in which the time two measures are regressed on the time one measures, have become the standard method of analyzing the design. Currently, methods to rule out third-variable causation are little used. Several analysts have argued that two waves are insufficient to obtain much information about how processes unfold over time.},
  isbn = {978-0-470-01319-9},
  langid = {english},
  keywords = {change,measurement error,multiple regression,third variables},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\A4C5SCJT\\Kenny - 2005 - Cross-Lagged Panel Design.pdf;C\:\\Users\\Driver\\Zotero\\storage\\T9EFYT8A\\0470013192.html}
}

@book{Kenny2006Dyadic,
  title = {Dyadic Data Analysis},
  author = {Kenny, David A. and Kashy, Deborah A. and Cook, William L.},
  date = {2006},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {978-1606237631}
}

@book{KloedenPlaten1992,
  title = {Numerical Solution of Stochastic Differential Equations},
  author = {Kloeden, Peter E. and Platen, Eckhard},
  date = {1992},
  publisher = {Springer},
  location = {Berlin},
  isbn = {978-3-540-54062-5}
}

@book{Lutkepohl2005,
  title = {New Introduction to Multiple Time Series Analysis},
  author = {Lütkepohl, Helmut},
  date = {2005},
  publisher = {Springer},
  location = {Berlin},
  isbn = {978-3-540-40172-8}
}

@article{NakagawaSchielzeth2013,
  title = {A General and Simple Method for Obtaining {{R}}² from Generalized Linear Mixed-Effects Models},
  author = {Nakagawa, Shinichi and Schielzeth, Holger},
  date = {2013},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {4},
  number = {2},
  pages = {133--142},
  doi = {10.1111/j.2041-210X.2012.00261.x}
}

@article{neale2016openmx,
  title = {{{OpenMx}} 2.0: Extended Structural Equation and Statistical Modeling},
  shorttitle = {Openmx 2.0},
  author = {Neale, Michael C. and Hunter, Michael D. and Pritikin, Joshua N. and Zahery, Mahsa and Brick, Timothy R. and Kirkpatrick, Robert M. and Estabrook, Ryne and Bates, Timothy C. and Maes, Hermine H. and Boker, Steven M.},
  date = {2016-06-01},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {81},
  number = {2},
  pages = {535--549},
  issn = {1860-0980},
  doi = {10.1007/s11336-014-9435-8},
  abstract = {The new software package OpenMx~2.0 for structural equation and other statistical modeling is introduced and its features are described. OpenMx is evolving in a modular direction and now allows a mix-and-match computational approach that separates model expectations from fit functions and optimizers. Major backend architectural improvements include a move to swappable open-source optimizers such as the newly written CSOLNP. Entire new methodologies such as item factor analysis and state space modeling have been implemented. New model expectation functions including support for the expression of models in LISREL syntax and a simplified multigroup expectation function are available. Ease-of-use improvements include helper functions to standardize model parameters and compute their Jacobian-based standard errors, access to model components through standard R \$ mechanisms, and improved tab completion from within the R Graphical User Interface.},
  langid = {english},
  keywords = {and Law,Assessment,Assessment Testing and Evaluation,behavior genetics,Behavorial Science,big data,Education,full information maximum likelihood,item factor analysis,latent class analysis,mixture distribution,optimization,ordinal data,path analysis,Path Analysis,Psychometrics,Public Policy,state space modeling,State space modeling,Statistical Theory and Methods,Statistics for Social Science,Statistics for Social Science Behavorial Science Education Public Policy and Law,structural equation modeling,Structural equation modeling,substance use data analysis,Testing and Evaluation,time series},
  file = {C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\crosslagged\\Neale et al_2016_OpenMx 2.pdf;C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\heirarchical ct article\\Neale et al_2016_OpenMx 2.pdf;C\:\\Users\\Driver\\Zotero\\storage\\3I3UJBRT\\Neale et al_2016_OpenMx 2.pdf;C\:\\Users\\Driver\\Zotero\\storage\\68U79X6Z\\Neale et al_2016_OpenMx 2.pdf;C\:\\Users\\Driver\\Zotero\\storage\\6VUDSRNF\\10.html}
}

@article{oravecz2011hierarchical,
  title = {A Hierarchical Latent Stochastic Differential Equation Model for Affective Dynamics},
  author = {Oravecz, Zita and Tuerlinckx, Francis and Vandekerckhove, Joachim},
  date = {2011},
  journaltitle = {Psychological Methods},
  volume = {16},
  number = {4},
  pages = {468--490},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/a0024375},
  abstract = {In this article a continuous-time stochastic model (the Ornstein–Uhlenbeck process) is presented to model the perpetually altering states of the core affect, which is a 2-dimensional concept underlying all our affective experiences. The process model that we propose can account for the temporal changes in core affect on the latent level. The key parameters of the model are the average position (also called home base), the variances and covariances of the process, and the regulatory mechanisms that keep the process in the vicinity of the average position. To account for individual differences, the model is extended hierarchically. A particularly novel contribution is that in principle all parameters of the stochastic process (not only the mean but also its variance and the regulatory parameters) are allowed to differ between individuals. In this way, the aim is to understand the affective dynamics of single individuals and at the same time investigate how these individuals differ from one another. The final model is a continuous-time state-space model for repeated measurement data taken at possibly irregular time points. Both time-invariant and time-varying covariates can be included to investigate sources of individual differences. As an illustration, the model is applied to a diary study measuring core affect repeatedly for several individuals (thereby generating intensive longitudinal data). (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Emotions,Individual Differences,Statistical Probability,Stochastic Modeling},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\S68XQN2B\\Oravecz et al. - 2011 - A hierarchical latent stochastic differential equation model for affective dynamics.pdf;C\:\\Users\\Driver\\Zotero\\storage\\HYUYHVMR\\2011-16738-001.html}
}

@article{ou2019whats,
  title = {What’s for Dynr: A Package for Linear and Nonlinear Dynamic Modeling in {{R}}},
  shorttitle = {What’s for Dynr},
  author = {Ou, Lu and Hunter, Michael D. and Chow, Sy-Miin},
  date = {2019-06},
  journaltitle = {The R journal},
  shortjournal = {R J},
  volume = {11},
  number = {1},
  eprint = {34306735},
  eprinttype = {pubmed},
  pages = {91--111},
  issn = {2073-4859},
  doi = {10.32614/rj-2019-012},
  abstract = {Intensive longitudinal data in the behavioral sciences are often noisy, multivariate in nature, and may involve multiple units undergoing regime switches by showing discontinuities interspersed with continuous dynamics. Despite increasing interest in using linear and nonlinear differential/difference equation models with regime switches, there has been a scarcity of software packages that are fast and freely accessible. We have created an R package called dynr that can handle a broad class of linear and nonlinear discrete- and continuous-time models, with regime-switching properties and linear Gaussian measurement functions, in C, while maintaining simple and easy-to-learn model specification functions in R. We present the mathematical and computational bases used by the dynr R package, and present two illustrative examples to demonstrate the unique features of dynr.},
  pmcid = {PMC8297742},
  file = {C:\Users\Driver\Zotero\storage\E9X49HNP\Ou et al. - 2019 - What’s for dynr A Package for Linear and Nonlinear Dynamic Modeling in R.pdf}
}

@incollection{oud2018first,
  title = {First- and Higher-Order Continuous Time Models for Arbitrary n Using Sem},
  booktitle = {Continuous Time Modeling in the Behavioral and Related Sciences},
  author = {Oud, Johan H. L. and Voelkle, Manuel C. and Driver, Charles C.},
  editor = {family=Montfort, given=Kees, prefix=van, useprefix=true and Oud, Johan H.L. and Voelkle, Manuel C.},
  date = {2018},
  pages = {1--26},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-77219-6_1},
  abstract = {In this chapter we review continuous time series modeling and estimation by extended structural equation models (SEM) for single subjects and N {$>$} 1. First-order as well as higher-order models will be dealt with. Both will be handled by the general state space approach which reformulates higher-order models as first-order models. In addition to the basic model, the extensions of exogenous variables and traits (random intercepts) will be introduced. The connection between continuous time and discrete time for estimating the model by SEM will be made by the exact discrete model (EDM). It is by the EDM that the exact estimation procedure in this chapter differentiates from many approximate procedures found in the literature. The proposed analysis procedure will be applied to the well-known Wolfer sunspot data, an N = 1 time series that has been analyzed by several continuous time analysts in the past. The analysis will be carried out by ctsem, an R-package for continuous time modeling that interfaces to OpenMx, and the results will be compared to those reported in the previous studies.},
  isbn = {978-3-319-77219-6},
  langid = {english},
  file = {C:\Users\Driver\Dropbox\MPIB\zotero\charlie\Oud et al_2018_First- and Higher-Order Continuous Time Models for Arbitrary N Using SEM.pdf}
}

@book{OudVoelkle2018Book,
  title = {Continuous Time Modeling in the Behavioral and Related Sciences},
  editor = {Oud, Johan H. L. and Voelkle, Manuel C.},
  date = {2018},
  publisher = {Springer},
  location = {Cham},
  doi = {10.1007/978-3-319-77219-6},
  isbn = {978-3-319-77218-9}
}

@article{robinaugh2021invisible,
  title = {Invisible Hands and Fine Calipers: A Call to Use Formal Theory as a Toolkit for Theory Construction},
  shorttitle = {Invisible Hands and Fine Calipers},
  author = {Robinaugh, Donald J. and Haslbeck, Jonas M. B. and Ryan, Oisín and Fried, Eiko I. and Waldorp, Lourens J.},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {725--743},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620974697},
  abstract = {In recent years, a growing chorus of researchers has argued that psychological theory is in a state of crisis: Theories are rarely developed in a way that indicates an accumulation of knowledge. Paul Meehl raised this very concern more than 40 years ago. Yet in the ensuing decades, little has improved. We aim to chart a better path forward for psychological theory by revisiting Meehl’s criticisms, his proposed solution, and the reasons his solution failed to meaningfully change the status of psychological theory. We argue that Meehl identified serious shortcomings in our evaluation of psychological theories and that his proposed solution would substantially strengthen theory testing. However, we also argue that Meehl failed to provide researchers with the tools necessary to construct the kinds of rigorous theories his approach required. To advance psychological theory, we must equip researchers with tools that allow them to better generate, evaluate, and develop their theories. We argue that formal theories provide this much-needed set of tools, equipping researchers with tools for thinking, evaluating explanation, enhancing measurement, informing theory development, and promoting the collaborative construction of psychological theories.},
  langid = {english},
  file = {C:\Users\Driver\Zotero\storage\DSYU3GV3\Robinaugh et al. - 2021 - Invisible Hands and Fine Calipers A Call to Use Formal Theory as a Toolkit for Theory Construction.pdf}
}

@article{rohrer2023these,
  title = {These Are Not the Effects You Are Looking for: Causality and the within-/between-Persons Distinction in Longitudinal Data Analysis},
  shorttitle = {These Are Not the Effects You Are Looking For},
  author = {Rohrer, Julia M. and Murayama, Kou},
  date = {2023-01-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {6},
  number = {1},
  pages = {25152459221140842},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/25152459221140842},
  abstract = {In psychological science, researchers often pay particular attention to the distinction between within- and between-persons relationships in longitudinal data analysis. Here, we aim to clarify the relationship between the within- and between-persons distinction and causal inference and show that the distinction is informative but does not play a decisive role in causal inference. Our main points are threefold. First, within-persons data are not necessary for causal inference; for example, between-persons experiments can inform about (average) causal effects. Second, within-persons data are not sufficient for causal inference; for example, time-varying confounders can lead to spurious within-persons associations. Finally, despite not being sufficient, within-persons data can be tremendously helpful for causal inference. We provide pointers to help readers navigate the more technical literature on longitudinal models and conclude with a call for more conceptual clarity: Instead of letting statistical models dictate which substantive questions researchers ask, researchers should start with well-defined theoretical estimands, which in turn determine both study design and data analysis.},
  langid = {english},
  file = {C:\Users\Driver\Zotero\storage\HUQQ8NFM\Rohrer and Murayama - 2023 - These Are Not the Effects You Are Looking for Causality and the Within-Between-Persons Distinction.pdf}
}

@article{ryan2022time,
  title = {Time to Intervene: {{A}} Continuous-Time Approach to Network Analysis and Centrality},
  shorttitle = {Time to Intervene},
  author = {Ryan, Oisín and Hamaker, Ellen L.},
  date = {2022},
  journaltitle = {Psychometrika},
  volume = {87},
  number = {1},
  pages = {214--252},
  publisher = {Springer},
  doi = {10.1007/s11336-021-09767-0},
  keywords = {centrality,continuous-time modeling,dynamical network analysis,experience sampling methodology,intensive longitudinal data},
  file = {C\:\\Users\\Driver\\Dropbox\\MPIB\\zotero\\crosslagged\\updates\\Ryan_Hamaker_2022_Time to Intervene.pdf;C\:\\Users\\Driver\\Zotero\\storage\\K66CCNNA\\Ryan_Hamaker_2021_Time to Intervene.pdf}
}

@article{vangeert2011contributiona,
  title = {The Contribution of Complex Dynamic Systems to Development},
  author = {family=Geert, given=Paul, prefix=van, useprefix=true},
  date = {2011},
  journaltitle = {Child Development Perspectives},
  volume = {5},
  number = {4},
  pages = {273--278},
  issn = {1750-8606},
  doi = {10.1111/j.1750-8606.2011.00197.x},
  abstract = {Abstract— As development is an example of a complex dynamic system (CDS), the theory of CDS can make important contributions to our understanding of the developmental process. However, mainstream research in developmental psychology uses an empirical paradigm that is at odds with what it is purported to explain, namely, that development is a complex dynamic process. Although the number of studies that focus on a process-oriented and dynamic approach of development is growing, this article argues that the field is in need of a theoretical and methodological paradigm shift.},
  langid = {english},
  keywords = {complexity,developmental processes,dynamic systems,generalization,null hypothesis},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\FQG6KQBB\\van Geert - 2011 - The Contribution of Complex Dynamic Systems to Development.pdf;C\:\\Users\\Driver\\Zotero\\storage\\9FAG79MT\\j.1750-8606.2011.00197.html}
}

@article{Voelkle2012CTSEM,
  title = {An {{SEM}} Approach to Continuous Time Modeling of Panel Data: {{Relating}} Authoritarianism and Anomia},
  author = {Voelkle, Manuel C. and Oud, Johan H. L. and Davidov, Eldad and Schmidt, Peter},
  date = {2012},
  journaltitle = {Psychological Methods},
  volume = {17},
  number = {2},
  pages = {176--192},
  doi = {10.1037/a0027543}
}

@article{voelkle2013continuousa,
  title = {Continuous Time Modelling with Individually Varying Time Intervals for Oscillating and Non-Oscillating Processes},
  author = {Voelkle, Manuel C. and Oud, Johan H. L.},
  date = {2013},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  volume = {66},
  number = {1},
  pages = {103--126},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.2012.02043.x},
  abstract = {When designing longitudinal studies, researchers often aim at equal intervals. In practice, however, this goal is hardly ever met, with different time intervals between assessment waves and different time intervals between individuals being more the rule than the exception. One of the reasons for the introduction of continuous time models by means of structural equation modelling has been to deal with irregularly spaced assessment waves (e.g., Oud \& Delsing, 2010). In the present paper we extend the approach to individually varying time intervals for oscillating and non-oscillating processes. In addition, we show not only that equal intervals are unnecessary but also that it can be advantageous to use unequal sampling intervals, in particular when the sampling rate is low. Two examples are provided to support our arguments. In the first example we compare a continuous time model of a bivariate coupled process with varying time intervals to a standard discrete time model to illustrate the importance of accounting for the exact time intervals. In the second example the effect of different sampling intervals on estimating a damped linear oscillator is investigated by means of a Monte Carlo simulation. We conclude that it is important to account for individually varying time intervals, and encourage researchers to conceive of longitudinal studies with different time intervals within and between individuals as an opportunity rather than a problem.},
  langid = {english},
  file = {C\:\\Users\\Driver\\Zotero\\storage\\8S3FTACA\\Voelkle and Oud - 2013 - Continuous time modelling with individually varying time intervals for oscillating and non-oscillati.pdf;C\:\\Users\\Driver\\Zotero\\storage\\9QD9JBVK\\j.2044-8317.2012.02043.html}
}

@article{wilson2019ten,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  editor = {Behrens, Timothy E},
  date = {2019-11-26},
  journaltitle = {eLife},
  volume = {8},
  pages = {e49547},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.49547},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  keywords = {computational modeling,model fitting,reproducibility,validation},
  file = {C:\Users\Driver\Zotero\storage\PFJ8D54F\Wilson and Collins - 2019 - Ten simple rules for the computational modeling of behavioral data.pdf}
}

@article{yarkoni2017choosing,
  title = {Choosing Prediction over Explanation in Psychology: Lessons from Machine Learning},
  shorttitle = {Choosing Prediction over Explanation in Psychology},
  author = {Yarkoni, Tal and Westfall, Jacob},
  date = {2017-11-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691617693393},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology’s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  langid = {english},
  file = {C:\Users\Driver\Zotero\storage\EIMT3HV8\Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology Lessons From Machine Learning.pdf}
}
